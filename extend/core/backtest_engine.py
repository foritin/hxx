import itertools
import time
from multiprocessing import Pool, shared_memory
import numpy as np
from typing import Union, Optional
from pathlib import Path
from extend.core.backtest_logger import BacktestLogger
from extend.core.backtest_data import BacktestDataManager
from extend.core.backtest_report import BacktestReportGenerator
from extend.core.backtest_result import BacktestResultCalculator
from extend.api.strategy_api import StrategyAPI, create_strategy_api
from extend.data.data_source import MultiDataSource
from extend.utils import BaseTools
from extend.core.backtest_config import StrategyConfig


class SharedMemoryDataFrame:
    """è‡ªå®šä¹‰DataFrameç±»ï¼Œç›´æ¥ä½¿ç”¨å…±äº«å†…å­˜è€Œä¸å¤åˆ¶æ•°æ®"""
    
    def __init__(self, data_dict, length):
        self.data_dict = data_dict
        self.length = length
        self.columns = list(data_dict.keys())
    
    def __len__(self):
        return self.length
    
    def row(self, index, named=True):
        """æ¨¡æ‹Ÿpolars DataFrameçš„rowæ–¹æ³•"""
        if named:
            return {col: self.data_dict[col][index] for col in self.columns}
        else:
            return [self.data_dict[col][index] for col in self.columns]
    
    def is_empty(self):
        return self.length == 0
    
    def __getitem__(self, key):
        """æ”¯æŒå¤šç§ç´¢å¼•æ–¹å¼"""
        if isinstance(key, str):
            # åˆ—è®¿é—®: data["close"]
            return self.data_dict[key]
        elif isinstance(key, tuple) and len(key) == 2:
            # ä½ç½®è®¿é—®: data[i, "close"]
            row_idx, col_name = key
            return self.data_dict[col_name][row_idx]
        elif isinstance(key, int):
            # è¡Œè®¿é—®: data[i] (è¿”å›è¯¥è¡Œçš„Series)
            return {col: self.data_dict[col][key] for col in self.columns}
        else:
            raise ValueError(f"Unsupported key type: {type(key)}")
    
    def to_pandas(self):
        """è½¬æ¢ä¸ºpandas DataFrameï¼ˆå¦‚æœéœ€è¦ï¼‰"""
        import pandas as pd
        return pd.DataFrame(self.data_dict)
    
    def to_numpy(self):
        """è½¬æ¢ä¸ºnumpyæ•°ç»„"""
        import numpy as np
        return np.column_stack([self.data_dict[col] for col in self.columns])
    
    def slice(self, start, length):
        """åˆ‡ç‰‡æ“ä½œï¼Œæ¨¡æ‹Ÿpolarsçš„sliceæ–¹æ³•"""
        sliced_data = {}
        for col in self.columns:
            sliced_data[col] = self.data_dict[col][start:start+length]
        return SharedMemoryDataFrame(sliced_data, length)


class MultiSourceBacktester:

    def __init__(self, config_file_path: Union[str, Path]):

        yaml_config = BaseTools.load_yaml_config(config_file_path)
        self.strategy_config = StrategyConfig(**yaml_config)

        self.base_config = self.strategy_config.base_config
        self.trade_config = self.strategy_config.trade_config
        self.symbol_configs = self.strategy_config.symbol_configs
        self.optimization_params = self.strategy_config.optimization_params if hasattr(self.strategy_config, "optimization_params") else None

        self.initialize_flag = False
        self._last_multi_data_source: Optional[MultiDataSource] = None

        # å›æµ‹ç»“æœ
        self.results = {}

        # æ—¥å¿—ç®¡ç†å™¨
        self.logger: Optional[BacktestLogger] = None

        # æ•°æ®ç®¡ç†å™¨
        self.data_manager: Optional[BacktestDataManager] = None

        # å›æµ‹ç»“æœè®¡ç®—å™¨
        self.result_calculator: Optional[BacktestResultCalculator] = None

        # æŠ¥å‘Šç”Ÿæˆå™¨
        self.report_generator: Optional[BacktestReportGenerator] = None

        # å‚æ•°ä¼˜åŒ–æ ‡å¿—
        self._in_optimization_mode = False

    def initialize(self):

        # åˆå§‹åŒ–æ—¥å¿—ç®¡ç†å™¨
        self.logger = BacktestLogger(debug_mode=self.base_config.debug)
        # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        self.data_manager = BacktestDataManager(logger=self.logger, trade_config=self.trade_config)
        self.report_generator = BacktestReportGenerator(logger=self.logger)
        self.result_calculator = BacktestResultCalculator(logger=self.logger)
        self.logger.log_message("Backtest engine initialized.")
        self.initialize_flag = True

    def run_backtest(self, strategy_module_path):
        assert self.logger and self.data_manager and self.result_calculator and self.report_generator, "Backtest engine not initialized."
        # æ•°æ®åˆå§‹åŒ–
        self.logger.log_message("Fetching data for backtest...")
        multi_data_source = self.data_manager.build_datasources(symbol_configs=self.symbol_configs).align_data(
            align_index=self.base_config.align_data,
            fill_method=self.base_config.fill_method,
        )
        if len(multi_data_source) == 0:
            self.logger.log_message("No data fetched for backtest.")
            return {}
        self.logger.log_message("Running backtest...")
        min_length = min([len(source.data) for source in multi_data_source.data_sources if not source.data.is_empty()])
        self.logger.log_message(f"Backtest data length: {min_length}")

        # è®°å½•å›æµ‹å¼€å§‹æ—¶é—´
        start_time = time.time()

        # ç­–ç•¥ä¸Šä¸‹æ–‡
        strategy_params = self.strategy_config.strategy_params.model_dump() if self.strategy_config.strategy_params else {}
        context = {"data": multi_data_source, "log": self.logger.log_message, "params": strategy_params}
        api = create_strategy_api(context)

        import importlib
        module_path, func_name = strategy_module_path.rsplit('.', 1)
        module = importlib.import_module(module_path)
        strategy_func_or_class = getattr(module, func_name)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç­–ç•¥ç±»
        if hasattr(strategy_func_or_class, '__bases__') and strategy_func_or_class.__name__.endswith('Strategy'):
            # è¿™æ˜¯ä¸€ä¸ªç­–ç•¥ç±»ï¼Œéœ€è¦å®ä¾‹åŒ–
            strategy_instance = strategy_func_or_class(strategy_params)
            strategy_func = strategy_instance.run
        else:
            strategy_func = strategy_func_or_class

        if hasattr(strategy_func, "initialize"):
            self.logger.log_message("Initializing strategy...")
            strategy_func.initialize(api)

        # loop strategy
        for i in range(min_length):
            for ds in multi_data_source.data_sources:
                if not ds.data.is_empty() and i < len(ds.data):
                    ds.current_idx = i
                    row = ds.data.row(i, named=True)
                    ds.current_price = row["close"]
                    ds.current_datetime = row["datetime"]
                    ds._process_pending_orders(log_callback=self.logger.log_message)
            # æ˜¾ç¤ºè¿›åº¦æ¡ï¼ˆä»…åœ¨éä¼˜åŒ–æ¨¡å¼ä¸‹æ˜¾ç¤ºï¼‰
            # if not self._in_optimization_mode:
            #     current_time = time.time()
            #     if current_time - progress_last_update >= progress_update_interval:
            #         progress_last_update = current_time
            #         progress = float(i + 1) / min_length
            #         filled_length = int(progress_bar_length * progress)
            #         bar = "â–ˆ" * filled_length + "-" * (progress_bar_length - filled_length)

            #         # æ·»åŠ æ¯åˆ†é’Ÿå¤„ç†çš„Kçº¿æ•°
            #         elapsed = current_time - start_time
            #         if elapsed > 0:
            #             bars_per_minute = (i + 1) / elapsed * 60
            #             estimated_time = (min_length - i - 1) * elapsed / (i + 1)

            #             # æ¸…ç©ºå½“å‰è¡Œå¹¶æ˜¾ç¤ºè¿›åº¦æ¡
            #             print(f"\rå›æµ‹è¿›åº¦: |{bar}| {progress*100:.1f}% ({i+1}/{min_length}) [{bars_per_minute:.0f}Kçº¿/åˆ†é’Ÿ] [å‰©ä½™: {estimated_time:.1f}ç§’]", end="", flush=True)

            # è°ƒè¯•ä¿¡æ¯ï¼ˆä»…åœ¨debug=Trueæ—¶æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—ï¼‰
            if self.base_config.debug and i % 100 == 0:
                self.logger.log_message(f"å¤„ç†ç¬¬ {i}/{min_length} æ¡æ•°æ®")
                for j, ds in enumerate(multi_data_source.data_sources):
                    if not ds.data.is_empty() and i < len(ds.data):
                        self.logger.log_message(f"æ•°æ®æº #{j}: æ—¶é—´={ds.current_datetime}, ä»·æ ¼={ds.current_price:.2f}, æŒä»“={ds.current_pos}")

            # è¿è¡Œç­–ç•¥
            strategy_func(api)
        end_time = time.time()
        elapsed_time = end_time - start_time
        self.logger.log_message(f"å›æµ‹å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f} ç§’")
        # è®¡ç®—å›æµ‹ç»“æœ
        result_dict = self.result_calculator.generate_report(multi_data_source)

        self._last_multi_data_source = multi_data_source

        return result_dict


    def run_backtest_optimization(self, strategy_module_path, max_processes: int =4):
        optimization_params = self.strategy_config.optimization_params.to_dict()
        params_names = list(optimization_params.keys())
        params_values = list(optimization_params.values())
        param_combinations = [
            dict(zip(params_names, combo)) 
            for combo in itertools.product(*params_values)
        ]
        self.logger.log_message(f"ğŸ¯ ç”Ÿæˆ {len(param_combinations)} ä¸ªå‚æ•°ç»„åˆ")
    
        # 2. å‡†å¤‡æ•°æ®ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰
        multi_data_source = self.data_manager.build_datasources(
            symbol_configs=self.symbol_configs
        ).align_data(
            align_index=self.base_config.align_data,
            fill_method=self.base_config.fill_method,
        )
    

        # 3. åˆ›å»ºå…±äº«å†…å­˜
        shared_data = {}
        shared_memories = {}
        
        for ds in multi_data_source.data_sources:
            if not ds.data.is_empty():
                ds_key = f"{ds.symbol}_{ds.kline_period}"
                shared_data[ds_key] = {}
                shared_memories[ds_key] = {}
                
                # å…±äº«OHLCVæ•°æ®å’Œdatetime
                for col in ['datetime', 'open', 'high', 'low', 'close', 'volume']:
                    if col in ds.data.columns:
                        data_array = ds.data[col].to_numpy()
                        
                        # åˆ›å»ºå…±äº«å†…å­˜
                        shm = shared_memory.SharedMemory(create=True, size=data_array.nbytes)
                        shared_array = np.ndarray(data_array.shape, dtype=data_array.dtype, buffer=shm.buf)
                        shared_array[:] = data_array
                        
                        shared_memories[ds_key][col] = shm
                        shared_data[ds_key][col] = {
                            'name': shm.name,
                            'shape': data_array.shape,
                            'dtype': str(data_array.dtype)
                        }
        
        self.logger.log_message("ğŸ“¦ å…±äº«å†…å­˜åˆ›å»ºå®Œæˆ")
        
        # 4. è®¾ç½®ä¼˜åŒ–æ¨¡å¼
        original_debug = self.base_config.debug
        self.base_config.debug = False  # ä¼˜åŒ–æœŸé—´å…³é—­è¯¦ç»†æ—¥å¿—
        self._in_optimization_mode = True
        try:
            # 5. å¹¶è¡Œæ‰§è¡Œ
            start_time = time.time()
            
            tasks = [
                (shared_data, params, self.strategy_config.strategy_params.model_dump(), strategy_module_path)
                for params in param_combinations
            ]
            
            # é™åˆ¶æ¯ä¸ªworkeræœ€å¤šå¤„ç†20ä¸ªä»»åŠ¡åé‡å¯ï¼Œæ›´ç§¯æåœ°æ§åˆ¶å†…å­˜
            with Pool(max_processes, maxtasksperchild=20) as pool:
                # ä½¿ç”¨imap_unorderedæ¥æ˜¾ç¤ºå®æ—¶è¿›åº¦
                results = []
                completed = 0
                total_tasks = len(tasks)
                
                self.logger.log_message(f"ğŸš€ å¼€å§‹å¤„ç† {total_tasks} ä¸ªå‚æ•°ç»„åˆ...")
                self.logger.log_message(f"âš™ï¸  ä½¿ç”¨ {max_processes} ä¸ªè¿›ç¨‹ï¼Œæ­£åœ¨å¯åŠ¨workerè¿›ç¨‹...")
                
                # è®¾ç½®è¾ƒå°çš„chunksizeå¹¶é™åˆ¶æ¯ä¸ªworkerçš„ä»»åŠ¡æ•°é‡ï¼ˆé˜²æ­¢å†…å­˜ç´¯ç§¯ï¼‰
                # maxtasksperchildé™åˆ¶æ¯ä¸ªworkeræœ€å¤šå¤„ç†20ä¸ªä»»åŠ¡åé‡å¯
                worker_pids = set()  # è·Ÿè¸ªworkerè¿›ç¨‹ID
                
                for result in pool.imap_unordered(self.optimization_worker, tasks, chunksize=1):
                    results.append(result)
                    completed += 1
                    
                    # ç¬¬ä¸€ä¸ªä»»åŠ¡å®Œæˆæ—¶çš„ç‰¹æ®Šæç¤º
                    if completed == 1:
                        self.logger.log_message("âœ… ç¬¬ä¸€ä¸ªä»»åŠ¡å®Œæˆï¼Œworkerè¿›ç¨‹å¯åŠ¨æˆåŠŸï¼")
                    
                    # ä¼˜åŒ–åçš„è¿›åº¦æŠ¥å‘Šï¼šæ¯50ä¸ªä»»åŠ¡æˆ–æ¯1%è¿›åº¦æ˜¾ç¤ºä¸€æ¬¡
                    if completed % 50 == 0 or completed % max(1, total_tasks // 100) == 0:
                        progress = (completed / total_tasks) * 100
                        valid_count = len([r for r in results if r is not None])
                        elapsed = time.time() - start_time
                        rate = completed / elapsed if elapsed > 0 else 0
                        eta = (total_tasks - completed) / rate if rate > 0 else 0
                        
                        self.logger.log_message(
                            f"ğŸ“Š è¿›åº¦: {completed}/{total_tasks} ({progress:.1f}%) | "
                            f"æœ‰æ•ˆç»“æœ: {valid_count} | æˆåŠŸç‡: {(valid_count/completed)*100:.1f}% | "
                            f"é€Ÿåº¦: {rate:.1f}ä»»åŠ¡/ç§’ | é¢„è®¡å‰©ä½™: {eta/60:.1f}åˆ†é’Ÿ"
                        )
            
            # è¿‡æ»¤æœ‰æ•ˆç»“æœ
            valid_results = [r for r in results if r is not None]
            
            elapsed_time = time.time() - start_time
            self.logger.log_message(
                f"âœ… ä¼˜åŒ–å®Œæˆ: {len(valid_results)}/{len(param_combinations)} æˆåŠŸ, "
                f"è€—æ—¶ {elapsed_time:.2f}ç§’"
            )
            
            # 6. ç»“æœåˆ†æ
            if valid_results:
                self._analyze_results(valid_results)
            
            return valid_results
            
        finally:
            # 7. æ¸…ç†
            self.base_config.debug = original_debug
            self._in_optimization_mode = False
            
            # æ¸…ç†å…±äº«å†…å­˜
            for ds_memories in shared_memories.values():
                for shm in ds_memories.values():
                    try:
                        shm.close()
                        shm.unlink()
                    except:
                        pass



    def optimization_worker(self, args):
        shared_data, test_params, base_params, strategy_module_path = args
        
        # ç®€å•çš„workerå¼€å§‹æ—¥å¿—
        import os
        worker_id = os.getpid()
        
        # ç›‘æ§å†…å­˜ä½¿ç”¨ï¼ˆéªŒè¯å…±äº«å†…å­˜æ•ˆæœï¼‰
        process = None
        start_memory = 0
        try:
            import psutil
            process = psutil.Process(worker_id)
            start_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            # åªåœ¨å†…å­˜å¼‚å¸¸æ—¶è­¦å‘Š
            if start_memory > 1000:  # è¶…è¿‡1GBè¯´æ˜æœ‰é—®é¢˜
                print(f"ğŸš¨ WORKER_{worker_id}: æ–°workerå†…å­˜å¼‚å¸¸! å¼€å§‹å†…å­˜={start_memory:.1f}MB, å‚æ•°={test_params}")
        except:
            pass  # é™é»˜å¤„ç†å†…å­˜ç›‘æ§å¤±è´¥
        
        try:
            import polars as pl
            from extend.api.strategy_api import create_strategy_api
            from extend.data.data_source import DataSource, MultiDataSource
            
            # åˆ›å»ºMultiDataSourceï¼Œä½¿ç”¨çœŸæ­£çš„å…±äº«å†…å­˜ï¼ˆæ— å¤åˆ¶ï¼‰
            multi_data_source = MultiDataSource()
            shared_memories_in_worker = {}  # ä¿å­˜å…±äº«å†…å­˜å¼•ç”¨ï¼Œé˜²æ­¢è¢«åƒåœ¾å›æ”¶
            
            for ds_key, data_info in shared_data.items():
                symbol, period = ds_key.split('_', 1)
                
                # é‡å»ºæ•°æ®æ•°ç»„ - å…³é”®ï¼šä¸è°ƒç”¨.copy()
                data_dict = {}
                shared_memories_in_worker[ds_key] = {}
                
                for col, info in data_info.items():
                    existing_shm = shared_memory.SharedMemory(name=info['name'])
                    # ç›´æ¥ä½¿ç”¨å…±äº«å†…å­˜ï¼Œä¸å¤åˆ¶ï¼
                    data_array = np.ndarray(
                        info['shape'], 
                        dtype=np.dtype(info['dtype']), 
                        buffer=existing_shm.buf
                    )
                    # ä¿å­˜å…±äº«å†…å­˜å¼•ç”¨ï¼Œé˜²æ­¢è¢«åƒåœ¾å›æ”¶
                    shared_memories_in_worker[ds_key][col] = existing_shm
                    data_dict[col] = data_array
                
                # å°è¯•ä½¿ç”¨polarsï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨SharedMemoryDataFrame
                try:
                    # å°è¯•ä½¿ç”¨polars DataFrameï¼ˆå¯èƒ½ä¼šå¤åˆ¶æ•°æ®ï¼Œä½†åŠŸèƒ½å®Œæ•´ï¼‰
                    df = pl.DataFrame(data_dict)
                    
                    # åªåœ¨å¼‚å¸¸æƒ…å†µä¸‹æ‰“å°
                    if len(df) == 0:
                        print(f"âš ï¸ WORKER_{worker_id}: polars DataFrameä¸ºç©ºï¼")
                    elif "close" not in df.columns:
                        print(f"âš ï¸ WORKER_{worker_id}: polars DataFrameç¼ºå°‘closeåˆ—ï¼")
                        
                except Exception as e:
                    # å¦‚æœpolarså¤±è´¥ï¼Œä½¿ç”¨SharedMemoryDataFrame
                    df = SharedMemoryDataFrame(data_dict, len(data_dict['datetime']))
                    print(f"âš ï¸ WORKER_{worker_id}: polarså¤±è´¥ï¼Œä½¿ç”¨SharedMemoryDataFrame: {e}")
                    
                    # åªåœ¨å¼‚å¸¸æƒ…å†µä¸‹éªŒè¯
                    if len(df) == 0:
                        print(f"âš ï¸ WORKER_{worker_id}: SharedMemoryDataFrameä¸ºç©ºï¼")
                
                # ä½¿ç”¨add_data_sourceæ–¹æ³•æ¥æ­£ç¡®è®¾ç½®double_dict
                multi_data_source.add_data_source(symbol, period, df)
            
            # 2. åˆå¹¶å‚æ•°
            strategy_params = {**base_params, **test_params}
            
            # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„trade_configç”¨äºèµ„é‡‘åˆ†é…
            from extend.core.backtest_config import TradeConfig
            fund_amount = strategy_params.get('Fund', 100000)
            temp_trade_config = TradeConfig(
                total_capital=fund_amount,  # ä½¿ç”¨ç­–ç•¥å‚æ•°ä¸­çš„èµ„é‡‘
                commission=0.00025,  # ä¸yamlé…ç½®ä¸€è‡´
                slippage=0.0,
                total_margin_rate=0.3  # ä¸yamlé…ç½®ä¸€è‡´
            )
            multi_data_source.allocate_fund(temp_trade_config)
            
            # 3. åˆ›å»ºAPIå¹¶è¿è¡Œç­–ç•¥
            context = {
                "data": multi_data_source,
                "log": lambda x: None,  # ä¼˜åŒ–æ¨¡å¼ä¸‹å®Œå…¨é™é»˜
                "params": strategy_params
            }
            api = create_strategy_api(context)
            
            # 4. åŠ¨æ€å¯¼å…¥ç­–ç•¥å‡½æ•°æˆ–ç±»
            import importlib
            module_path, func_name = strategy_module_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            strategy_func_or_class = getattr(module, func_name)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç­–ç•¥ç±»
            if hasattr(strategy_func_or_class, '__bases__') and strategy_func_or_class.__name__.endswith('Strategy'):
                # è¿™æ˜¯ä¸€ä¸ªç­–ç•¥ç±»ï¼Œéœ€è¦å®ä¾‹åŒ–
                strategy_instance = strategy_func_or_class(strategy_params)
                
                # éªŒè¯å…³é”®å‚æ•°ï¼Œé¿å…åç»­è®¡ç®—é”™è¯¯
                M = strategy_params.get('M', 60)
                S = strategy_params.get('S', 10)
                if S != 0:
                    period_1 = max(1, int(M/S))
                    if period_1 <= 0:
                        # å‚æ•°æ— æ•ˆï¼Œç›´æ¥è¿”å›Noneè·³è¿‡æ­¤å‚æ•°ç»„åˆï¼ˆé™é»˜è·³è¿‡ï¼‰
                        return None
                
                strategy_func = strategy_instance.run
            else:
                # è¿™æ˜¯ä¸€ä¸ªæ™®é€šå‡½æ•°
                strategy_func = strategy_func_or_class
            
            # 5. ç®€åŒ–çš„å›æµ‹å¾ªç¯
            min_length = min([len(ds.data) for ds in multi_data_source.data_sources])
            for i in range(min_length):
                for ds in multi_data_source.data_sources:
                    ds.current_idx = i
                    row = ds.data.row(i, named=True)
                    ds.current_price = row["close"]
                    ds.current_datetime = row["datetime"]
                    ds._process_pending_orders(log_callback=None)
                
                strategy_func(api)
            
            # 6. ä½¿ç”¨ä¸“ä¸šçš„ç»“æœè®¡ç®—å™¨è®¡ç®—è¯¦ç»†ç»“æœ
            from extend.core.backtest_result import BacktestResultCalculator
            
            result_calculator = BacktestResultCalculator(logger=None)  # ä¼˜åŒ–æœŸé—´ä¸æ‰“å°æ—¥å¿—
            results = result_calculator.generate_report(multi_data_source)
            performance = results.get('_overall_performance', {})
            
            # æå–å…³é”®æŒ‡æ ‡ç”¨äºä¼˜åŒ–
            if performance and results:
                net_value = performance.get('total_final_equity', 0) / performance.get('total_initial_capital', 1) if performance.get('total_initial_capital', 1) > 0 else 1
                total_trades = performance.get('total_trades', 0)
                total_net_profit = performance.get('total_net_profit', 0)
                sharpe_ratio = performance.get('weighted_sharpe_ratio', 0)
                max_drawdown_pct = performance.get('weighted_max_drawdown_pct', 0)
                win_rate = performance.get('overall_win_rate', 0)
                
                # æå–æœˆæ”¶ç›Šç‡æŒ‡æ ‡
                monthly_return_avg = performance.get('overall_monthly_return_avg', 0)
                monthly_return_std = performance.get('overall_monthly_return_std', 0)
                monthly_stability_score = performance.get('overall_monthly_stability', 0)
                
                # è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡ï¼ˆå¤åˆ©æ–¹å¼ï¼Œä½¿ç”¨365å¤©ï¼‰
                total_initial_capital = performance.get('total_initial_capital', 1)
                total_final_equity = performance.get('total_final_equity', 0)
                if results:
                    # è·å–äº¤æ˜“æ—¥æ€»æ•°ï¼ˆä»ç¬¬ä¸€ä¸ªæ•°æ®æºï¼‰
                    first_ds_result = next(iter([v for k, v in results.items() if k != '_overall_performance']), {})
                    trading_days = first_ds_result.get('trading_days', 365)
                    trading_years = trading_days / 365 if trading_days > 0 else 1
                    # å¤åˆ©å¹´åŒ–æ”¶ç›Šç‡ï¼š((æœŸæœ«/æœŸåˆ)^(1/å¹´æ•°) - 1) * 100
                    annual_return = ((total_final_equity / total_initial_capital) ** (1/trading_years) - 1) * 100 if trading_years > 0 and total_initial_capital > 0 else 0
                else:
                    annual_return = 0
                    trading_days = 0
            else:
                # å¦‚æœæ²¡æœ‰äº¤æ˜“ï¼Œè¿”å›åŸºç¡€å€¼
                net_value = 1.0
                total_trades = 0
                total_net_profit = 0
                sharpe_ratio = 0
                max_drawdown_pct = 0
                win_rate = 0
                monthly_return_avg = 0
                monthly_return_std = 0
                monthly_stability_score = 0
                annual_return = 0
                trading_days = 0
            
            result = {
                'params': test_params,
                'net_value': net_value,
                'annual_return': annual_return,
                'trading_days': trading_days,
                'total_trades': total_trades,
                'total_net_profit': total_net_profit,
                'sharpe_ratio': sharpe_ratio,
                'max_drawdown_pct': max_drawdown_pct,
                'win_rate': win_rate,
                'monthly_return_avg': monthly_return_avg,
                'monthly_return_std': monthly_return_std,
                'monthly_stability_score': monthly_stability_score,
                'detailed_results': results,  # åŒ…å«è¯¦ç»†çš„æ¯ä¸ªæ•°æ®æºçš„ç»“æœ
                'performance': performance     # åŒ…å«æ•´ä½“æ€§èƒ½æŒ‡æ ‡
            }
            
            # è®°å½•å®Œæˆæ—¶çš„å†…å­˜ä½¿ç”¨ï¼ˆåªåœ¨å†…å­˜å¢é•¿å¼‚å¸¸æ—¶æ‰“å°ï¼‰
            if process:
                try:
                    end_memory = process.memory_info().rss / 1024 / 1024  # MB
                    memory_increase = end_memory - start_memory
                    # åªåœ¨å†…å­˜å¢é•¿è¿‡å¤§æ—¶æ‰“å°è­¦å‘Š
                    if memory_increase > 50:  # è¶…è¿‡50MBå¢é•¿æ—¶æ‰è­¦å‘Š
                        print(f"âš ï¸ WORKER_{worker_id}: å†…å­˜å¢é•¿å¼‚å¸¸! å‡€å€¼={net_value:.4f}, äº¤æ˜“={total_trades}, å†…å­˜å¢é•¿={memory_increase:.1f}MB")
                except:
                    pass  # é™é»˜å¤„ç†å†…å­˜ç›‘æ§å¤±è´¥
            return result
            
        except Exception as e:
            # åªåœ¨ä¸¥é‡é”™è¯¯æ—¶æ‰“å°ï¼Œå‡å°‘å™ªéŸ³
            if "Memory" in str(e) or "ImportError" in str(e) or "NameError" in str(e):
                print(f"âŒ WORKER_{worker_id}: ä¸¥é‡é”™è¯¯ - {str(e)}")
            return None
        
        finally:
            # æ¸…ç†å…±äº«å†…å­˜å¼•ç”¨ï¼ˆä½†ä¸unlinkï¼Œç”±ä¸»è¿›ç¨‹è´Ÿè´£ï¼‰
            if 'shared_memories_in_worker' in locals():
                for ds_memories in shared_memories_in_worker.values():
                    for shm in ds_memories.values():
                        try:
                            shm.close()  # åªå…³é—­å½“å‰è¿›ç¨‹çš„è¿æ¥
                        except:
                            pass
            
            # å¼ºåˆ¶æ¸…ç†å¤§å¯¹è±¡ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
            try:
                # æ¸…ç†ç­–ç•¥ç›¸å…³å¯¹è±¡
                if 'strategy_instance' in locals():
                    del strategy_instance
                if 'strategy_func' in locals():
                    del strategy_func
                if 'api' in locals():
                    del api
                    
                # æ¸…ç†æ•°æ®æºå¯¹è±¡
                if 'multi_data_source' in locals():
                    # å°è¯•æ¸…ç†DataSourceä¸­çš„æ•°æ®
                    for ds in multi_data_source.data_sources:
                        if hasattr(ds, 'data'):
                            ds.data = None
                        if hasattr(ds, 'trades'):
                            ds.trades = []
                    del multi_data_source
                
                # æ¸…ç†ç»“æœå¯¹è±¡å’ŒDataFrame
                if 'results' in locals():
                    del results
                if 'data_dict' in locals():
                    del data_dict
                
                # æ¸…ç†ä»»ä½•pandas DataFrameç¼“å­˜
                try:
                    import pandas as pd
                    # æ¸…ç†pandaså†…éƒ¨ç¼“å­˜
                    if hasattr(pd, 'core') and hasattr(pd.core, 'common') and hasattr(pd.core.common, '_values_from_object'):
                        # è¿™æ˜¯pandasçš„å†…éƒ¨æ¸…ç†ï¼Œä½†å¯èƒ½ä¸æ€»æ˜¯æœ‰æ•ˆ
                        pass
                except:
                    pass
                
                # å¼ºåˆ¶åƒåœ¾å›æ”¶ï¼ˆé™é»˜æ‰§è¡Œï¼‰
                import gc
                gc.collect()
                
            except Exception as cleanup_error:
                # åªåœ¨ä¸¥é‡çš„æ¸…ç†é”™è¯¯æ—¶æ‰“å°
                if "Memory" in str(cleanup_error) or "Access" in str(cleanup_error):
                    print(f"âš ï¸ WORKER_{worker_id}: ä¸¥é‡æ¸…ç†é”™è¯¯: {cleanup_error}")
                pass  # æ¸…ç†å¤±è´¥ä¸å½±å“ä¸»æµç¨‹


    def _analyze_results(self, results):
        """åˆ†æä¼˜åŒ–ç»“æœï¼ˆä½¿ç”¨BacktestResultCalculatorè¿›è¡Œè®¡ç®—ï¼‰"""
        if not results:
            return
        
        # ä½¿ç”¨BacktestResultCalculatorè¿›è¡Œå¢å¼ºæŒ‡æ ‡è®¡ç®—
        from extend.core.backtest_result import BacktestResultCalculator
        calculator = BacktestResultCalculator(logger=None)  # ä¸´æ—¶è®¡ç®—å™¨ï¼Œä¸éœ€è¦æ—¥å¿—
        
        # å¢å¼ºç»“æœæ•°æ®
        enhanced_results = calculator.enhance_results_with_metrics(results)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        stats = calculator.calculate_statistics(enhanced_results)
        
        # å¼€å§‹è¾“å‡ºåˆ†æç»“æœ
        self.logger.log_message("=" * 70)
        self.logger.log_message("ğŸ† å‚æ•°ä¼˜åŒ–ç»“æœåˆ†æ")
        self.logger.log_message("=" * 70)
        
        # 1. æŒ‰å¹´åŒ–æ”¶ç›Šç‡æ’åºï¼ˆä¸»è¦æŒ‡æ ‡ï¼‰
        sorted_by_annual_return = calculator.get_sorted_results(enhanced_results, 'annual_return', 5)
        self._log_ranking_results("ğŸ“ˆ æŒ‰å¹´åŒ–æ”¶ç›Šç‡æ’åº", sorted_by_annual_return, 
                                  lambda r: f"å‡€å€¼={r['net_value']:.4f} | å¤æ™®={r.get('sharpe_ratio', 0):.2f} | èƒœç‡={r.get('win_rate', 0):.2%} | å›æ’¤={r.get('max_drawdown_pct', 0):.2%} | äº¤æ˜“={r['total_trades']} | äº¤æ˜“æ—¥={r.get('trading_days', 0)} | æœˆå‡æ”¶ç›Š={r.get('monthly_return_avg', 0):.2f}% | æœˆæ”¶ç›Šæ ‡å·®={r.get('monthly_return_std', 0):.2f}% | æœˆç¨³å®šæ€§={r.get('monthly_stability_score', 0):.2f}")
        
        # 2. æŒ‰å¤æ™®æ¯”ç‡æ’åº
        sorted_by_sharpe = calculator.get_sorted_results(enhanced_results, 'sharpe_ratio', 5)
        if sorted_by_sharpe:
            self._log_ranking_results("ğŸ“Š æŒ‰å¤æ™®æ¯”ç‡æ’åº", sorted_by_sharpe,
                                      lambda r: f"å‡€å€¼={r['net_value']:.4f} | å¤æ™®={r.get('sharpe_ratio', 0):.2f} | èƒœç‡={r.get('win_rate', 0):.2%} | å›æ’¤={r.get('max_drawdown_pct', 0):.2%} | äº¤æ˜“={r['total_trades']} | äº¤æ˜“æ—¥={r.get('trading_days', 0)} | æœˆå‡æ”¶ç›Š={r.get('monthly_return_avg', 0):.2f}% | æœˆæ”¶ç›Šæ ‡å·®={r.get('monthly_return_std', 0):.2f}% | æœˆç¨³å®šæ€§={r.get('monthly_stability_score', 0):.2f}")
        
        # 3. æŒ‰æœ€å¤§å›æ’¤æ’åºï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        sorted_by_drawdown = calculator.get_sorted_results(enhanced_results, 'max_drawdown_pct', 5)
        if sorted_by_drawdown:
            self._log_ranking_results("ğŸ“‰ æŒ‰æœ€å¤§å›æ’¤æ’åºï¼ˆæœ€å°å›æ’¤ï¼‰", sorted_by_drawdown,
                                      lambda r: f"å‡€å€¼={r['net_value']:.4f} | å¤æ™®={r.get('sharpe_ratio', 0):.2f} | èƒœç‡={r.get('win_rate', 0):.2%} | å›æ’¤={r.get('max_drawdown_pct', 0):.2%} | äº¤æ˜“={r['total_trades']} | äº¤æ˜“æ—¥={r.get('trading_days', 0)} | æœˆå‡æ”¶ç›Š={r.get('monthly_return_avg', 0):.2f}% | æœˆæ”¶ç›Šæ ‡å·®={r.get('monthly_return_std', 0):.2f}% | æœˆç¨³å®šæ€§={r.get('monthly_stability_score', 0):.2f}")
        
        # 4. æŒ‰èƒœç‡æ’åº
        sorted_by_winrate = calculator.get_sorted_results(enhanced_results, 'win_rate', 5)
        if sorted_by_winrate:
            self._log_ranking_results("ğŸ¯ æŒ‰èƒœç‡æ’åº", sorted_by_winrate,
                                      lambda r: f"å‡€å€¼={r['net_value']:.4f} | å¤æ™®={r.get('sharpe_ratio', 0):.2f} | èƒœç‡={r.get('win_rate', 0):.2%} | å›æ’¤={r.get('max_drawdown_pct', 0):.2%} | äº¤æ˜“={r['total_trades']} | äº¤æ˜“æ—¥={r.get('trading_days', 0)} | æœˆå‡æ”¶ç›Š={r.get('monthly_return_avg', 0):.2f}% | æœˆæ”¶ç›Šæ ‡å·®={r.get('monthly_return_std', 0):.2f}% | æœˆç¨³å®šæ€§={r.get('monthly_stability_score', 0):.2f}")
        
        # 5. ç»¼åˆè¯„åˆ†æ’åº
        sorted_by_composite = calculator.get_sorted_results(enhanced_results, 'composite_score', 5)
        self._log_ranking_results("ğŸ† ç»¼åˆè¯„åˆ†æ’åº", sorted_by_composite,
                                  lambda r: f"ç»¼åˆè¯„åˆ†={r['composite_score']:.2f} | å‡€å€¼={r['net_value']:.4f} | å¤æ™®={r.get('sharpe_ratio', 0):.2f} | èƒœç‡={r.get('win_rate', 0):.2%} | å›æ’¤={r.get('max_drawdown_pct', 0):.2%} | äº¤æ˜“={r['total_trades']} | äº¤æ˜“æ—¥={r.get('trading_days', 0)} | æœˆå‡æ”¶ç›Š={r.get('monthly_return_avg', 0):.2f}% | æœˆæ”¶ç›Šæ ‡å·®={r.get('monthly_return_std', 0):.2f}% | æœˆç¨³å®šæ€§={r.get('monthly_stability_score', 0):.2f}")
        
        # æœ€ä¼˜å‚æ•°è¯¦ç»†ä¿¡æ¯ï¼ˆæŒ‰å¹´åŒ–æ”¶ç›Šç‡ï¼‰
        best = sorted_by_annual_return[0] if sorted_by_annual_return else enhanced_results[0]
        self._log_best_result_details(best)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self._log_optimization_statistics(stats)
        
        self.logger.log_message("=" * 70)
    
    def _log_ranking_results(self, title, results, format_func):
        """è¾“å‡ºæ’åç»“æœçš„é€šç”¨æ–¹æ³•"""
        self.logger.log_message(f"\n{title} Top 5:")
        self.logger.log_message("-" * 70)
        for i, result in enumerate(results, 1):
            params_str = ", ".join([f"{k}={v}" for k, v in result['params'].items()])
            metrics_str = format_func(result)
            self.logger.log_message(f"{i}. {metrics_str} | {params_str}")
    
    def _log_best_result_details(self, best):
        """è¾“å‡ºæœ€ä¼˜ç»“æœè¯¦ç»†ä¿¡æ¯"""
        self.logger.log_message(f"\nğŸ¥‡ æœ€ä¼˜å‚æ•°ç»„åˆï¼ˆæŒ‰å¹´åŒ–æ”¶ç›Šç‡ï¼‰:")
        self.logger.log_message("-" * 40)
        for k, v in best['params'].items():
            self.logger.log_message(f"  {k}: {v}")
        
        self.logger.log_message(f"\nğŸ“‹ æœ€ä¼˜ç»“æœè¯¦ç»†æŒ‡æ ‡:")
        self.logger.log_message(f"  å‡€å€¼: {best['net_value']:.4f}")
        self.logger.log_message(f"  å¹´åŒ–æ”¶ç›Šç‡: {best.get('annual_return', 0):.2f}%")
        self.logger.log_message(f"  å¤æ™®æ¯”ç‡: {best.get('sharpe_ratio', 0):.2f}")
        self.logger.log_message(f"  èƒœç‡: {best.get('win_rate', 0):.2%}")
        self.logger.log_message(f"  æœ€å¤§å›æ’¤: {best.get('max_drawdown_pct', 0):.2%}")
        self.logger.log_message(f"  äº¤æ˜“æ¬¡æ•°: {best['total_trades']}")
        self.logger.log_message(f"  å›æµ‹äº¤æ˜“æ—¥: {best.get('trading_days', 0)}")
        self.logger.log_message(f"  æœˆå¹³å‡æ”¶ç›Š: {best.get('monthly_return_avg', 0):.2f}%")
        self.logger.log_message(f"  æœˆæ”¶ç›Šæ ‡å‡†å·®: {best.get('monthly_return_std', 0):.2f}%")
        self.logger.log_message(f"  æœˆæ”¶ç›Šç¨³å®šæ€§: {best.get('monthly_stability_score', 0):.2f}")
        self.logger.log_message(f"  å‡€åˆ©æ¶¦: {best.get('total_net_profit', 0):.2f}")
    
    def _log_optimization_statistics(self, stats):
        """è¾“å‡ºä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯"""
        self.logger.log_message(f"\nğŸ“Š ä¼˜åŒ–ç»Ÿè®¡:")
        self.logger.log_message(f"  å‚æ•°ç»„åˆæ€»æ•°: {stats['total_combinations']}")
        self.logger.log_message(f"  æœ‰æ•ˆç»“æœæ•°: {stats['valid_results_count']}")
        self.logger.log_message(f"  å¹³å‡å‡€å€¼: {stats['avg_net_value']:.4f}")
        
        if 'avg_annual_return' in stats:
            self.logger.log_message(f"  å¹³å‡å¹´åŒ–æ”¶ç›Šç‡: {stats['avg_annual_return']:.2f}%")
        
        if 'avg_sharpe_ratio' in stats:
            self.logger.log_message(f"  å¹³å‡å¤æ™®æ¯”ç‡: {stats['avg_sharpe_ratio']:.2f}")
        
        if 'avg_win_rate' in stats:
            self.logger.log_message(f"  å¹³å‡èƒœç‡: {stats['avg_win_rate']:.2%}")
        
        # æœˆæ”¶ç›Šç‡ç»Ÿè®¡
        if 'avg_monthly_return' in stats:
            self.logger.log_message(f"  å¹³å‡æœˆæ”¶ç›Š: {stats['avg_monthly_return']:.2f}%")
            self.logger.log_message(f"  å¹³å‡æœˆæ”¶ç›Šæ ‡å‡†å·®: {stats['avg_monthly_std']:.2f}%")
            self.logger.log_message(f"  å¹³å‡æœˆæ”¶ç›Šç¨³å®šæ€§: {stats['avg_monthly_stability']:.2f}")

